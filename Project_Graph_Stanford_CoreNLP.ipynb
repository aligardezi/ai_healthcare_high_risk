{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6TDB21wCXKOd"
   },
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lHnbj_m0XW7e"
   },
   "source": [
    "This notebook contains steps to\n",
    "\n",
    "*   Use Stanford Core NLP to build entities and relationships for Anatomy Book\n",
    "*   Setup Neo4J Graph DB locally and load the entities and relationships\n",
    "*   Given a question, extracts all the relationships for entities in that question\n",
    "*   Connect to OpenAI\n",
    "*   Construct a Prompt. The Prompt should include the question as well as the entity relationships that were extracted\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AAdEOQToZXja"
   },
   "source": [
    "# Install the StanfordCoreNLP Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KDJuhKgcuuVN",
    "outputId": "3aac8fd4-dcf8-4bd5-a855-57069ff1a9c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stanfordcorenlp in c:\\users\\aliim\\anaconda3\\lib\\site-packages (3.9.1.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\aliim\\anaconda3\\lib\\site-packages (from stanfordcorenlp) (5.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\aliim\\anaconda3\\lib\\site-packages (from stanfordcorenlp) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aliim\\anaconda3\\lib\\site-packages (from requests->stanfordcorenlp) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aliim\\anaconda3\\lib\\site-packages (from requests->stanfordcorenlp) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aliim\\anaconda3\\lib\\site-packages (from requests->stanfordcorenlp) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aliim\\anaconda3\\lib\\site-packages (from requests->stanfordcorenlp) (2024.8.30)\n",
      "Requirement already satisfied: pycorenlp in c:\\users\\aliim\\anaconda3\\lib\\site-packages (0.3.0)\n",
      "Requirement already satisfied: requests in c:\\users\\aliim\\anaconda3\\lib\\site-packages (from pycorenlp) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aliim\\anaconda3\\lib\\site-packages (from requests->pycorenlp) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aliim\\anaconda3\\lib\\site-packages (from requests->pycorenlp) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aliim\\anaconda3\\lib\\site-packages (from requests->pycorenlp) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aliim\\anaconda3\\lib\\site-packages (from requests->pycorenlp) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "! pip install stanfordcorenlp\n",
    "! pip install pycorenlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mRwL8uB1ZPqe"
   },
   "source": [
    "# Start and Connect to the StanfordCoreNLP Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qeVsTUVF7X_E"
   },
   "outputs": [],
   "source": [
    "#before executing this code make sure to start the server\n",
    "# cd stanford-corenlp-full-2018-10-05\n",
    "# java -mx6g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -timeout 5000\n",
    "\n",
    "\n",
    "import os\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "\n",
    "# Start Stanford CoreNLP server\n",
    "nlp = StanfordCoreNLP('http://localhost:9000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nszoaMwmZdlx"
   },
   "source": [
    "# Utility Functions to extract the entities and relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-IYxjxJF7VMK"
   },
   "outputs": [],
   "source": [
    "def extract_entities(text):\n",
    "    props = {'annotators': 'tokenize,ssplit,pos,lemma,ner',\n",
    "             'pipelineLanguage': 'en',\n",
    "             'outputFormat': 'json'}\n",
    "    result = nlp.annotate(text, properties=props)\n",
    "    # Process the output to extract entities\n",
    "    entities = []\n",
    "    try:\n",
    "        import json\n",
    "        output = json.loads(result)\n",
    "        for sentence in output['sentences']:\n",
    "            for entity in sentence['entitymentions']:\n",
    "                entities.append({'text': entity['text'], 'label': entity['ner']})\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error processing JSON output from Stanford CoreNLP: {e}\")\n",
    "\n",
    "    return entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "id": "gfkPNUrOtLb4"
   },
   "outputs": [],
   "source": [
    "def extract_relationships(text):\n",
    "    props = {'annotators': 'tokenize,ssplit,pos,depparse,openie',\n",
    "             'pipelineLanguage': 'en'}\n",
    "    result = nlp.annotate(text, properties=props)\n",
    "    # Process the output to extract relationships\n",
    "    relationships = []\n",
    "    try:\n",
    "        import json\n",
    "        output = json.loads(result)\n",
    "        for sentence in output['sentences']:\n",
    "            for relation in sentence.get('openie', []):\n",
    "                relationships.append({\n",
    "                    'subject': relation['subject'],\n",
    "                    'relation': relation['relation'],\n",
    "                    'object': relation['object']\n",
    "                })\n",
    "    except:\n",
    "        print(\"Error processing JSON output from Stanford CoreNLP.\")\n",
    "\n",
    "    return relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lV7sQpou_fzu",
    "outputId": "1988d2c7-4e30-4b80-b0c4-d2b2c69a9ba1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing JSON output from Stanford CoreNLP: Expecting value: line 1 column 1 (char 0)\n",
      "Entities: []\n",
      "Relationships: [{'subject': 'John Doe', 'relation': 'was', 'object': 'diagnosed'}, {'subject': 'John Doe', 'relation': 'was diagnosed with', 'object': 'Type 2 diabetes mellitus'}, {'subject': 'John Doe', 'relation': 'was', 'object': \"diagnosed with Type 2 diabetes mellitus at St. John 's Hospital\"}, {'subject': 'St. John', 'relation': 'at', 'object': 'Hospital'}, {'subject': 'John Doe', 'relation': 'was diagnosed with', 'object': 'T2DM'}, {'subject': 'John Doe', 'relation': 'was diagnosed at', 'object': \"St. John 's Hospital\"}]\n"
     ]
    }
   ],
   "source": [
    "text = \"John Doe, was diagnosed with Type 2 diabetes mellitus (T2DM) and hypertension by Dr. Smith at St. John's Hospital\"\n",
    "entities = extract_entities(text)\n",
    "relationships = extract_relationships(text)\n",
    "\n",
    "print(\"Entities:\", entities)\n",
    "print(\"Relationships:\", relationships)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEqHshRVZyG2"
   },
   "source": [
    "# Install Neo4J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7kqGPlh5_3AG",
    "outputId": "c7425ca1-6dc4-40a6-abc1-f30e3ef4e010"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: neo4j in c:\\users\\aliim\\anaconda3\\lib\\site-packages (5.27.0)\n",
      "Requirement already satisfied: pytz in c:\\users\\aliim\\anaconda3\\lib\\site-packages (from neo4j) (2024.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install neo4j\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uo-L45Lyl5yf"
   },
   "source": [
    "# Neo4J Utility Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "RE8X_gzr_3sO"
   },
   "outputs": [],
   "source": [
    "# Please make sure to download Neo4j and start it locally. The Uri and the password will be available once Neo4J is started\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "# Connect to Neo4j\n",
    "uri = \"bolt://localhost:7687\"\n",
    "driver = GraphDatabase.driver(uri, auth=(\"neo4j\", \"hello1234\"))\n",
    "\n",
    "# Create nodes and relationships in Neo4j\n",
    "def create_graph(tx, entities, relationships):\n",
    "    # Add entities as nodes\n",
    "    #for entity in entities:\n",
    "    #    print(entity[\"text\"])\n",
    "    # tx.run(\"MERGE (e:Entity {name: $name})\", name=entity[\"text\"])\n",
    "    for rel in relationships:\n",
    "        tx.run(\"MERGE (e:Entity {name: $name})\", name=rel[\"subject\"])\n",
    "        tx.run(\"MERGE (e:Entity {name: $name})\", name=rel[\"object\"])\n",
    "\n",
    "    # Add relationships as edges\n",
    "    for rel in relationships:\n",
    "        tx.run(\"\"\"\n",
    "        MATCH (e1:Entity {name: $source}), (e2:Entity {name: $target})\n",
    "        MERGE (e1)-[:RELATIONSHIP {type: $relation}]->(e2)\n",
    "        \"\"\", source=rel[\"subject\"], target=rel[\"object\"], relation=rel[\"relation\"])\n",
    "\n",
    "# Populate the graph\n",
    "def build_neo4j_graph(entities, relationships):\n",
    "    with driver.session() as session:\n",
    "        session.write_transaction(create_graph, entities, relationships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "w1ppYZfSG427"
   },
   "outputs": [],
   "source": [
    "def print_neo4j_graph():\n",
    "    \"\"\"\n",
    "    Prints the nodes and relationships in a Neo4j graph.\n",
    "\n",
    "    Args:\n",
    "        uri: The URI of the Neo4j database.\n",
    "        auth: Authentication credentials (username, password).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with driver.session() as session:\n",
    "            # Get all nodes\n",
    "            result = session.run(\"MATCH (n) RETURN n\")\n",
    "            nodes = [record[\"n\"] for record in result]\n",
    "\n",
    "            # Get all relationships\n",
    "            result = session.run(\"MATCH ()-[r]->() RETURN r\")\n",
    "            relationships = [record[\"r\"] for record in result]\n",
    "\n",
    "            # Print nodes\n",
    "            print(\"Nodes:\")\n",
    "            for node in nodes:\n",
    "                print(f\"  - {node.id}: {node.labels} - {node.get('properties', {})}\") # Print Node ID, labels and properties\n",
    "\n",
    "            # Print relationships\n",
    "            print(\"\\nRelationships:\")\n",
    "            for relationship in relationships:\n",
    "                print(f\"  - {relationship.id}: {relationship.type} - ({relationship.start_node.id}) -> ({relationship.end_node.id}) - {relationship.get('properties', {})}\") # Print relationship ID, type, start and end node and properties\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "MTAx9cqiAVXa"
   },
   "outputs": [],
   "source": [
    "def query_graph(entity_name):\n",
    "    with driver.session() as session:\n",
    "        query = \"\"\"\n",
    "        MATCH (e1:Entity {name: $name})-[r]->(e2:Entity)\n",
    "        RETURN e1.name AS source, r.type AS relation, e2.name AS target\n",
    "        \"\"\"\n",
    "        results = session.run(query, name=entity_name)\n",
    "        return [{\"source\": record[\"source\"], \"relation\": record[\"relation\"], \"target\": record[\"target\"]} for record in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "--mRaKqPAW4r"
   },
   "outputs": [],
   "source": [
    "def delete_graph():\n",
    "  with driver.session() as session:\n",
    "    query = \"\"\"\n",
    "    MATCH (n) DETACH DELETE n\n",
    "    \"\"\"\n",
    "    session.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8FSNeUmPrEZ-"
   },
   "source": [
    "# Extract Entities and relationships from the Anatomy Book and load in Neo4J Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IUz9icrZXJAp",
    "outputId": "60a8da68-89c7-4cb6-ecc8-9775e7833a21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\aliim\\anaconda3\\envs\\ai_healthcare_project\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\aliim\\anaconda3\\envs\\ai_healthcare_project\\lib\\site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\aliim\\anaconda3\\envs\\ai_healthcare_project\\lib\\site-packages (from datasets) (2.1.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\aliim\\anaconda3\\envs\\ai_healthcare_project\\lib\\site-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\aliim\\anaconda3\\envs\\ai_healthcare_project\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\aliim\\anaconda3\\envs\\ai_healthcare_project\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\aliim\\anaconda3\\envs\\ai_healthcare_project\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\aliim\\anaconda3\\envs\\ai_healthcare_project\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\aliim\\anaconda3\\envs\\ai_healthcare_project\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\aliim\\anaconda3\\envs\\ai_healthcare_project\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\users\\aliim\\anaconda3\\envs\\ai_healthcare_project\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\aliim\\anaconda3\\envs\\ai_healthcare_project\\lib\\site-packages (from datasets) (3.11.8)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\aliim\\anaconda3\\envs\\ai_healthcare_project\\lib\\site-packages (from datasets) (0.26.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\aliim\\anaconda3\\envs\\ai_healthcare_project\\lib\\site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\aliim\\anaconda3\\envs\\ai_healthcare_project\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\aliim\\anaconda3\\envs\\ai_healthcare_project\\lib\\site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\aliim\\anaconda3\\envs\\ai_healthcare_project\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\aliim\\anaconda3\\envs\\ai_healthcare_project\\lib\\site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\aliim\\anaconda3\\envs\\ai_healthcare_project\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\aliim\\anaconda3\\envs\\ai_healthcare_project\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\aliim\\anaconda3\\envs\\ai_healthcare_project\\lib\\site-packages (from aiohttp->datasets) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\aliim\\anaconda3\\envs\\ai_healthcare_project\\lib\\site-packages (from aiohttp->datasets) (1.18.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\aliim\\anaconda3\\envs\\ai_healthcare_project\\lib\\site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aliim\\anaconda3\\envs\\ai_healthcare_project\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aliim\\anaconda3\\envs\\ai_healthcare_project\\lib\\site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aliim\\anaconda3\\envs\\ai_healthcare_project\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aliim\\anaconda3\\envs\\ai_healthcare_project\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\aliim\\anaconda3\\envs\\ai_healthcare_project\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\aliim\\anaconda3\\envs\\ai_healthcare_project\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aliim\\anaconda3\\envs\\ai_healthcare_project\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\aliim\\anaconda3\\envs\\ai_healthcare_project\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aliim\\anaconda3\\envs\\ai_healthcare_project\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pq0ibMfpXJAq",
    "outputId": "d106dce3-a18b-4f80-8d0d-d3ca6293e019"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'subject': 'Anatomy', 'relation': 'includes', 'object': 'structures'}, {'subject': 'term anatomy', 'relation': 'mean', 'object': 'gross anatomy'}, {'subject': 'term anatomy', 'relation': 'used by', 'object': 'itself'}, {'subject': 'term anatomy', 'relation': 'mean', 'object': 'anatomy'}, {'subject': 'Microscopic anatomy', 'relation': 'is study of', 'object': 'cells'}, {'subject': 'anatomy', 'relation': 'also called', 'object': 'histology'}, {'subject': 'anatomy', 'relation': 'called', 'object': 'histology'}, {'subject': 'study', 'relation': 'using', 'object': 'microscope'}, {'subject': 'anatomy', 'relation': 'is study of', 'object': 'cells'}, {'subject': 'Microscopic anatomy', 'relation': 'is', 'object': 'study'}, {'subject': 'Microscopic anatomy', 'relation': 'called', 'object': 'histology'}, {'subject': 'Microscopic anatomy', 'relation': 'also called', 'object': 'histology'}, {'subject': 'anatomy', 'relation': 'is', 'object': 'study'}, {'subject': 'Anatomy', 'relation': 'leads physician toward', 'object': \"understanding of patient 's disease\"}, {'subject': 'she', 'relation': 'carrying out', 'object': 'examination'}, {'subject': 'he', 'relation': 'carrying out', 'object': 'examination'}, {'subject': 'she', 'relation': 'using', 'object': 'most advanced imaging techniques'}, {'subject': 'she', 'relation': 'carrying out', 'object': 'physical examination'}, {'subject': 'he', 'relation': 'carrying out', 'object': 'physical examination'}, {'subject': 'she', 'relation': 'using', 'object': 'advanced imaging techniques'}, {'subject': 'patient', 'relation': 'of', 'object': 'disease'}, {'subject': 'Anatomy', 'relation': 'leads', 'object': 'physician'}, {'subject': 'she', 'relation': 'using', 'object': 'imaging techniques'}, {'subject': 'Anatomy', 'relation': 'leads physician toward', 'object': 'understanding'}, {'subject': 'Anatomy', 'relation': 'is', 'object': 'important'}, {'subject': 'Anatomy', 'relation': 'is', 'object': 'also important'}]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"json\", data_files=r\"C:\\\\Users\\\\aliim\\projects\\\\files\\\\AI_Healthcare\\\\textbooks\\\\chunk\\\\Anatomy_Gray.jsonl\", split='train')\n",
    "index = 0\n",
    "for entry in dataset:\n",
    "    relationships = extract_relationships(entry[\"content\"])\n",
    "    build_neo4j_graph(None, relationships)\n",
    "    print(\"Done processing entry \" + str(index))\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C_wYb8KJAao5",
    "outputId": "326b9678-05ef-41bb-dac2-50d605a4f955"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\aliim\\anaconda3\\lib\\site-packages (1.57.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\aliim\\anaconda3\\lib\\site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\aliim\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\aliim\\anaconda3\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\aliim\\anaconda3\\lib\\site-packages (from openai) (0.8.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\aliim\\anaconda3\\lib\\site-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\aliim\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\aliim\\anaconda3\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\aliim\\anaconda3\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\aliim\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\aliim\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\aliim\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\aliim\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\aliim\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\aliim\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\aliim\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "! pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8VswWLCrmCnG"
   },
   "source": [
    "# Open AI Utility methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FFRUKIxHAc5H"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = \"\"\n",
    "\n",
    "def query_openai(prompt, model=\"gpt-4o\", temperature=0.7, max_tokens=200):\n",
    "    \"\"\"\n",
    "    Send a query to OpenAI's LLM and return the response.\n",
    "\n",
    "    Parameters:\n",
    "    - prompt (str): The query or instruction for the LLM.\n",
    "    - model (str): The model to use (e.g., \"gpt-4\", \"gpt-3.5-turbo\").\n",
    "    - temperature (float): Controls randomness (0.0 for deterministic, 1.0 for creative).\n",
    "    - max_tokens (int): Maximum number of tokens to generate in the response.\n",
    "\n",
    "    Returns:\n",
    "    - str: The LLM response.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except openai.error.OpenAIError as e:\n",
    "        return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qhkCnB53mHDQ"
   },
   "source": [
    "# Example: Ask Question, Extract Entity and Relationships, Ask OpenAI for response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-gao2_Y4Aexd",
    "outputId": "39aa9030-4b27-4536-ba97-985600effb36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A lesion causing compression of the facial nerve at the stylomastoid foramen will cause ipsilateral\n",
      "\n",
      "A. paralysis of the facial muscles.\n",
      "B. paralysis of the facial muscles and loss of taste.\n",
      "C. paralysis of the facial muscles, loss of taste and lacrimation.\n",
      "D. paralysis of the facial muscles, loss of taste, lacrimation and decreased salivation.\n",
      "\n",
      "\n",
      "Please use only the following information in the prompt to answer the question. Also please specify whether information from any other sources was used.\n",
      "lesion is proximal\n",
      "lesion is in brain\n",
      "lesion was on side\n",
      "lesion results in eye\n",
      "lesion be along course\n",
      "lesion is likely affected\n",
      "lesion possibly caused by hypersensitivity response to release\n",
      "lesion caused by hypersensitivity response to release\n",
      "lesion may develop In minority\n",
      "lesion possibly caused by hypersensitivity response to release in tissues\n",
      "lesion caused by hypersensitivity response to release in tissues\n",
      "lesion possibly caused by hypersensitivity response\n",
      "lesion caused by hypersensitivity response\n",
      "lesion caused by hypersensitivity response to release of metal ions in tissues\n",
      "lesion possibly caused by hypersensitivity response to release of metal ions in tissues\n",
      "lesion may develop In minority of patients\n",
      "lesion caused by hypersensitivity response to release of metal ions\n",
      "lesion possibly caused by hypersensitivity response to release of metal ions\n",
      "lesion possibly caused by hypersensitivity response to release of metal ions in adjacent tissues\n",
      "lesion caused by hypersensitivity response to release of metal ions in adjacent tissues\n",
      "lesion possibly caused by hypersensitivity response to release in adjacent tissues\n",
      "lesion caused by hypersensitivity response to release in adjacent tissues\n",
      "lesion is in area\n",
      "lesion may undergo evaluation\n",
      "lesion i.e. may undergo evaluation\n",
      "lesion was postulated in sacrum\n",
      "lesion was on left side\n",
      "lesion is below level\n",
      "lesion is below level of C5\n",
      "lesion is likely\n",
      "lesion was caused by aneurysm\n",
      "lesion is below level at level of C5\n",
      "lesion is below level of C5 at level of C5\n",
      "lesion is below level at level\n",
      "lesion is below level of C5 at level\n",
      "lesion was caused\n",
      "lesion was postulated\n",
      "lesion was postulated in left sacrum\n",
      "lesion was expansile\n",
      "lesion bronchoscopic evaluation of trachea\n",
      "lesion evaluation of trachea\n",
      "lesion may undergo bronchoscopic evaluation\n",
      "lesion i.e. may undergo bronchoscopic evaluation\n",
      "lesion may undergo evaluation of trachea\n",
      "lesion i.e. may undergo evaluation of trachea\n",
      "lesion i.e. may undergo bronchoscopic evaluation of trachea\n",
      "lesion may undergo bronchoscopic evaluation of trachea\n",
      "lesion be primary\n",
      "lesion was dull\n",
      "lesion is likely in iliac artery\n",
      "lesion is likely in left iliac artery\n",
      "lesion is likely in common iliac artery\n",
      "lesion is likely patient 's symptoms occur only\n",
      "lesion is likely patient 's symptoms occur on side only\n",
      "lesion is likely patient 's symptoms occur\n",
      "lesion is likely patient 's symptoms occur on left side\n",
      "lesion is likely patient 's symptoms occur on left side only\n",
      "lesion is likely in left common iliac artery\n",
      "lesion is likely patient 's symptoms occur on side\n",
      "lesion was dull to percussion\n",
      "lesion results in dry eye\n",
      "lesion is proximal to greater petrosal of nerve\n",
      "lesion is proximal to petrosal of nerve\n",
      "lesion is proximal to greater petrosal\n",
      "lesion is proximal to petrosal\n",
      "lesion be along course of oculomotor nerve\n",
      "lesion is in area of optic chiasm\n",
      "lesion is in area of chiasm\n",
      "lesion is proximal\n",
      "lesion is in brain\n",
      "lesion was on side\n",
      "lesion results in eye\n",
      "lesion be along course\n",
      "lesion is likely affected\n",
      "lesion possibly caused by hypersensitivity response to release\n",
      "lesion caused by hypersensitivity response to release\n",
      "lesion may develop In minority\n",
      "lesion possibly caused by hypersensitivity response to release in tissues\n",
      "lesion caused by hypersensitivity response to release in tissues\n",
      "lesion possibly caused by hypersensitivity response\n",
      "lesion caused by hypersensitivity response\n",
      "lesion caused by hypersensitivity response to release of metal ions in tissues\n",
      "lesion possibly caused by hypersensitivity response to release of metal ions in tissues\n",
      "lesion may develop In minority of patients\n",
      "lesion caused by hypersensitivity response to release of metal ions\n",
      "lesion possibly caused by hypersensitivity response to release of metal ions\n",
      "lesion possibly caused by hypersensitivity response to release of metal ions in adjacent tissues\n",
      "lesion caused by hypersensitivity response to release of metal ions in adjacent tissues\n",
      "lesion possibly caused by hypersensitivity response to release in adjacent tissues\n",
      "lesion caused by hypersensitivity response to release in adjacent tissues\n",
      "lesion is in area\n",
      "lesion may undergo evaluation\n",
      "lesion i.e. may undergo evaluation\n",
      "lesion was postulated in sacrum\n",
      "lesion was on left side\n",
      "lesion is below level\n",
      "lesion is below level of C5\n",
      "lesion is likely\n",
      "lesion was caused by aneurysm\n",
      "lesion is below level at level of C5\n",
      "lesion is below level of C5 at level of C5\n",
      "lesion is below level at level\n",
      "lesion is below level of C5 at level\n",
      "lesion was caused\n",
      "lesion was postulated\n",
      "lesion was postulated in left sacrum\n",
      "lesion was expansile\n",
      "lesion bronchoscopic evaluation of trachea\n",
      "lesion evaluation of trachea\n",
      "lesion may undergo bronchoscopic evaluation\n",
      "lesion i.e. may undergo bronchoscopic evaluation\n",
      "lesion may undergo evaluation of trachea\n",
      "lesion i.e. may undergo evaluation of trachea\n",
      "lesion i.e. may undergo bronchoscopic evaluation of trachea\n",
      "lesion may undergo bronchoscopic evaluation of trachea\n",
      "lesion be primary\n",
      "lesion was dull\n",
      "lesion is likely in iliac artery\n",
      "lesion is likely in left iliac artery\n",
      "lesion is likely in common iliac artery\n",
      "lesion is likely patient 's symptoms occur only\n",
      "lesion is likely patient 's symptoms occur on side only\n",
      "lesion is likely patient 's symptoms occur\n",
      "lesion is likely patient 's symptoms occur on left side\n",
      "lesion is likely patient 's symptoms occur on left side only\n",
      "lesion is likely in left common iliac artery\n",
      "lesion is likely patient 's symptoms occur on side\n",
      "lesion was dull to percussion\n",
      "lesion results in dry eye\n",
      "lesion is proximal to greater petrosal of nerve\n",
      "lesion is proximal to petrosal of nerve\n",
      "lesion is proximal to greater petrosal\n",
      "lesion is proximal to petrosal\n",
      "lesion be along course of oculomotor nerve\n",
      "lesion is in area of optic chiasm\n",
      "lesion is in area of chiasm\n",
      "lesion is proximal\n",
      "lesion is in brain\n",
      "lesion was on side\n",
      "lesion results in eye\n",
      "lesion be along course\n",
      "lesion is likely affected\n",
      "lesion possibly caused by hypersensitivity response to release\n",
      "lesion caused by hypersensitivity response to release\n",
      "lesion may develop In minority\n",
      "lesion possibly caused by hypersensitivity response to release in tissues\n",
      "lesion caused by hypersensitivity response to release in tissues\n",
      "lesion possibly caused by hypersensitivity response\n",
      "lesion caused by hypersensitivity response\n",
      "lesion caused by hypersensitivity response to release of metal ions in tissues\n",
      "lesion possibly caused by hypersensitivity response to release of metal ions in tissues\n",
      "lesion may develop In minority of patients\n",
      "lesion caused by hypersensitivity response to release of metal ions\n",
      "lesion possibly caused by hypersensitivity response to release of metal ions\n",
      "lesion possibly caused by hypersensitivity response to release of metal ions in adjacent tissues\n",
      "lesion caused by hypersensitivity response to release of metal ions in adjacent tissues\n",
      "lesion possibly caused by hypersensitivity response to release in adjacent tissues\n",
      "lesion caused by hypersensitivity response to release in adjacent tissues\n",
      "lesion is in area\n",
      "lesion may undergo evaluation\n",
      "lesion i.e. may undergo evaluation\n",
      "lesion was postulated in sacrum\n",
      "lesion was on left side\n",
      "lesion is below level\n",
      "lesion is below level of C5\n",
      "lesion is likely\n",
      "lesion was caused by aneurysm\n",
      "lesion is below level at level of C5\n",
      "lesion is below level of C5 at level of C5\n",
      "lesion is below level at level\n",
      "lesion is below level of C5 at level\n",
      "lesion was caused\n",
      "lesion was postulated\n",
      "lesion was postulated in left sacrum\n",
      "lesion was expansile\n",
      "lesion bronchoscopic evaluation of trachea\n",
      "lesion evaluation of trachea\n",
      "lesion may undergo bronchoscopic evaluation\n",
      "lesion i.e. may undergo bronchoscopic evaluation\n",
      "lesion may undergo evaluation of trachea\n",
      "lesion i.e. may undergo evaluation of trachea\n",
      "lesion i.e. may undergo bronchoscopic evaluation of trachea\n",
      "lesion may undergo bronchoscopic evaluation of trachea\n",
      "lesion be primary\n",
      "lesion was dull\n",
      "lesion is likely in iliac artery\n",
      "lesion is likely in left iliac artery\n",
      "lesion is likely in common iliac artery\n",
      "lesion is likely patient 's symptoms occur only\n",
      "lesion is likely patient 's symptoms occur on side only\n",
      "lesion is likely patient 's symptoms occur\n",
      "lesion is likely patient 's symptoms occur on left side\n",
      "lesion is likely patient 's symptoms occur on left side only\n",
      "lesion is likely in left common iliac artery\n",
      "lesion is likely patient 's symptoms occur on side\n",
      "lesion was dull to percussion\n",
      "lesion results in dry eye\n",
      "lesion is proximal to greater petrosal of nerve\n",
      "lesion is proximal to petrosal of nerve\n",
      "lesion is proximal to greater petrosal\n",
      "lesion is proximal to petrosal\n",
      "lesion be along course of oculomotor nerve\n",
      "lesion is in area of optic chiasm\n",
      "lesion is in area of chiasm\n",
      "lesion is proximal\n",
      "lesion is in brain\n",
      "lesion was on side\n",
      "lesion results in eye\n",
      "lesion be along course\n",
      "lesion is likely affected\n",
      "lesion possibly caused by hypersensitivity response to release\n",
      "lesion caused by hypersensitivity response to release\n",
      "lesion may develop In minority\n",
      "lesion possibly caused by hypersensitivity response to release in tissues\n",
      "lesion caused by hypersensitivity response to release in tissues\n",
      "lesion possibly caused by hypersensitivity response\n",
      "lesion caused by hypersensitivity response\n",
      "lesion caused by hypersensitivity response to release of metal ions in tissues\n",
      "lesion possibly caused by hypersensitivity response to release of metal ions in tissues\n",
      "lesion may develop In minority of patients\n",
      "lesion caused by hypersensitivity response to release of metal ions\n",
      "lesion possibly caused by hypersensitivity response to release of metal ions\n",
      "lesion possibly caused by hypersensitivity response to release of metal ions in adjacent tissues\n",
      "lesion caused by hypersensitivity response to release of metal ions in adjacent tissues\n",
      "lesion possibly caused by hypersensitivity response to release in adjacent tissues\n",
      "lesion caused by hypersensitivity response to release in adjacent tissues\n",
      "lesion is in area\n",
      "lesion may undergo evaluation\n",
      "lesion i.e. may undergo evaluation\n",
      "lesion was postulated in sacrum\n",
      "lesion was on left side\n",
      "lesion is below level\n",
      "lesion is below level of C5\n",
      "lesion is likely\n",
      "lesion was caused by aneurysm\n",
      "lesion is below level at level of C5\n",
      "lesion is below level of C5 at level of C5\n",
      "lesion is below level at level\n",
      "lesion is below level of C5 at level\n",
      "lesion was caused\n",
      "lesion was postulated\n",
      "lesion was postulated in left sacrum\n",
      "lesion was expansile\n",
      "lesion bronchoscopic evaluation of trachea\n",
      "lesion evaluation of trachea\n",
      "lesion may undergo bronchoscopic evaluation\n",
      "lesion i.e. may undergo bronchoscopic evaluation\n",
      "lesion may undergo evaluation of trachea\n",
      "lesion i.e. may undergo evaluation of trachea\n",
      "lesion i.e. may undergo bronchoscopic evaluation of trachea\n",
      "lesion may undergo bronchoscopic evaluation of trachea\n",
      "lesion be primary\n",
      "lesion was dull\n",
      "lesion is likely in iliac artery\n",
      "lesion is likely in left iliac artery\n",
      "lesion is likely in common iliac artery\n",
      "lesion is likely patient 's symptoms occur only\n",
      "lesion is likely patient 's symptoms occur on side only\n",
      "lesion is likely patient 's symptoms occur\n",
      "lesion is likely patient 's symptoms occur on left side\n",
      "lesion is likely patient 's symptoms occur on left side only\n",
      "lesion is likely in left common iliac artery\n",
      "lesion is likely patient 's symptoms occur on side\n",
      "lesion was dull to percussion\n",
      "lesion results in dry eye\n",
      "lesion is proximal to greater petrosal of nerve\n",
      "lesion is proximal to petrosal of nerve\n",
      "lesion is proximal to greater petrosal\n",
      "lesion is proximal to petrosal\n",
      "lesion be along course of oculomotor nerve\n",
      "lesion is in area of optic chiasm\n",
      "lesion is in area of chiasm\n",
      "lesion is proximal\n",
      "lesion is in brain\n",
      "lesion was on side\n",
      "lesion results in eye\n",
      "lesion be along course\n",
      "lesion is likely affected\n",
      "lesion possibly caused by hypersensitivity response to release\n",
      "lesion caused by hypersensitivity response to release\n",
      "lesion may develop In minority\n",
      "lesion possibly caused by hypersensitivity response to release in tissues\n",
      "lesion caused by hypersensitivity response to release in tissues\n",
      "lesion possibly caused by hypersensitivity response\n",
      "lesion caused by hypersensitivity response\n",
      "lesion caused by hypersensitivity response to release of metal ions in tissues\n",
      "lesion possibly caused by hypersensitivity response to release of metal ions in tissues\n",
      "lesion may develop In minority of patients\n",
      "lesion caused by hypersensitivity response to release of metal ions\n",
      "lesion possibly caused by hypersensitivity response to release of metal ions\n",
      "lesion possibly caused by hypersensitivity response to release of metal ions in adjacent tissues\n",
      "lesion caused by hypersensitivity response to release of metal ions in adjacent tissues\n",
      "lesion possibly caused by hypersensitivity response to release in adjacent tissues\n",
      "lesion caused by hypersensitivity response to release in adjacent tissues\n",
      "lesion is in area\n",
      "lesion may undergo evaluation\n",
      "lesion i.e. may undergo evaluation\n",
      "lesion was postulated in sacrum\n",
      "lesion was on left side\n",
      "lesion is below level\n",
      "lesion is below level of C5\n",
      "lesion is likely\n",
      "lesion was caused by aneurysm\n",
      "lesion is below level at level of C5\n",
      "lesion is below level of C5 at level of C5\n",
      "lesion is below level at level\n",
      "lesion is below level of C5 at level\n",
      "lesion was caused\n",
      "lesion was postulated\n",
      "lesion was postulated in left sacrum\n",
      "lesion was expansile\n",
      "lesion bronchoscopic evaluation of trachea\n",
      "lesion evaluation of trachea\n",
      "lesion may undergo bronchoscopic evaluation\n",
      "lesion i.e. may undergo bronchoscopic evaluation\n",
      "lesion may undergo evaluation of trachea\n",
      "lesion i.e. may undergo evaluation of trachea\n",
      "lesion i.e. may undergo bronchoscopic evaluation of trachea\n",
      "lesion may undergo bronchoscopic evaluation of trachea\n",
      "lesion be primary\n",
      "lesion was dull\n",
      "lesion is likely in iliac artery\n",
      "lesion is likely in left iliac artery\n",
      "lesion is likely in common iliac artery\n",
      "lesion is likely patient 's symptoms occur only\n",
      "lesion is likely patient 's symptoms occur on side only\n",
      "lesion is likely patient 's symptoms occur\n",
      "lesion is likely patient 's symptoms occur on left side\n",
      "lesion is likely patient 's symptoms occur on left side only\n",
      "lesion is likely in left common iliac artery\n",
      "lesion is likely patient 's symptoms occur on side\n",
      "lesion was dull to percussion\n",
      "lesion results in dry eye\n",
      "lesion is proximal to greater petrosal of nerve\n",
      "lesion is proximal to petrosal of nerve\n",
      "lesion is proximal to greater petrosal\n",
      "lesion is proximal to petrosal\n",
      "lesion be along course of oculomotor nerve\n",
      "lesion is in area of optic chiasm\n",
      "lesion is in area of chiasm\n",
      "lesion is proximal\n",
      "lesion is in brain\n",
      "lesion was on side\n",
      "lesion results in eye\n",
      "lesion be along course\n",
      "lesion is likely affected\n",
      "lesion possibly caused by hypersensitivity response to release\n",
      "lesion caused by hypersensitivity response to release\n",
      "lesion may develop In minority\n",
      "lesion possibly caused by hypersensitivity response to release in tissues\n",
      "lesion caused by hypersensitivity response to release in tissues\n",
      "lesion possibly caused by hypersensitivity response\n",
      "lesion caused by hypersensitivity response\n",
      "lesion caused by hypersensitivity response to release of metal ions in tissues\n",
      "lesion possibly caused by hypersensitivity response to release of metal ions in tissues\n",
      "lesion may develop In minority of patients\n",
      "lesion caused by hypersensitivity response to release of metal ions\n",
      "lesion possibly caused by hypersensitivity response to release of metal ions\n",
      "lesion possibly caused by hypersensitivity response to release of metal ions in adjacent tissues\n",
      "lesion caused by hypersensitivity response to release of metal ions in adjacent tissues\n",
      "lesion possibly caused by hypersensitivity response to release in adjacent tissues\n",
      "lesion caused by hypersensitivity response to release in adjacent tissues\n",
      "lesion is in area\n",
      "lesion may undergo evaluation\n",
      "lesion i.e. may undergo evaluation\n",
      "lesion was postulated in sacrum\n",
      "lesion was on left side\n",
      "lesion is below level\n",
      "lesion is below level of C5\n",
      "lesion is likely\n",
      "lesion was caused by aneurysm\n",
      "lesion is below level at level of C5\n",
      "lesion is below level of C5 at level of C5\n",
      "lesion is below level at level\n",
      "lesion is below level of C5 at level\n",
      "lesion was caused\n",
      "lesion was postulated\n",
      "lesion was postulated in left sacrum\n",
      "lesion was expansile\n",
      "lesion bronchoscopic evaluation of trachea\n",
      "lesion evaluation of trachea\n",
      "lesion may undergo bronchoscopic evaluation\n",
      "lesion i.e. may undergo bronchoscopic evaluation\n",
      "lesion may undergo evaluation of trachea\n",
      "lesion i.e. may undergo evaluation of trachea\n",
      "lesion i.e. may undergo bronchoscopic evaluation of trachea\n",
      "lesion may undergo bronchoscopic evaluation of trachea\n",
      "lesion be primary\n",
      "lesion was dull\n",
      "lesion is likely in iliac artery\n",
      "lesion is likely in left iliac artery\n",
      "lesion is likely in common iliac artery\n",
      "lesion is likely patient 's symptoms occur only\n",
      "lesion is likely patient 's symptoms occur on side only\n",
      "lesion is likely patient 's symptoms occur\n",
      "lesion is likely patient 's symptoms occur on left side\n",
      "lesion is likely patient 's symptoms occur on left side only\n",
      "lesion is likely in left common iliac artery\n",
      "lesion is likely patient 's symptoms occur on side\n",
      "lesion was dull to percussion\n",
      "lesion results in dry eye\n",
      "lesion is proximal to greater petrosal of nerve\n",
      "lesion is proximal to petrosal of nerve\n",
      "lesion is proximal to greater petrosal\n",
      "lesion is proximal to petrosal\n",
      "lesion be along course of oculomotor nerve\n",
      "lesion is in area of optic chiasm\n",
      "lesion is in area of chiasm\n",
      "taste was preserved\n",
      "taste fibers to two-thirds\n",
      "taste fibers to anterior two-thirds\n",
      "taste fibers to salivary glands\n",
      "taste parasympathetic fibers to salivary glands\n",
      "taste general sensation from vallate papillae\n",
      "taste sensation from vallate papillae\n",
      "taste was Importantly preserved\n",
      "taste fibers to two-thirds of tongue travel in chorda tympani nerve\n",
      "taste fibers to anterior two-thirds of tongue travel in chorda tympani nerve\n",
      "taste fibers to anterior two-thirds of tongue travel\n",
      "taste fibers to two-thirds of tongue travel\n",
      "taste was preserved\n",
      "taste fibers to two-thirds\n",
      "taste fibers to anterior two-thirds\n",
      "taste fibers to salivary glands\n",
      "taste parasympathetic fibers to salivary glands\n",
      "taste general sensation from vallate papillae\n",
      "taste sensation from vallate papillae\n",
      "taste was Importantly preserved\n",
      "taste fibers to two-thirds of tongue travel in chorda tympani nerve\n",
      "taste fibers to anterior two-thirds of tongue travel in chorda tympani nerve\n",
      "taste fibers to anterior two-thirds of tongue travel\n",
      "taste fibers to two-thirds of tongue travel\n",
      "\n",
      "Response: Based on the provided information, the relevant details are:\n",
      "\n",
      "- A lesion at the stylomastoid foramen affecting the facial nerve would primarily impact the motor function of the facial muscles.\n",
      "- The information suggests that taste fibers, specifically those to the anterior two-thirds of the tongue, travel in the chorda tympani nerve. This nerve joins the facial nerve proximal to the stylomastoid foramen, meaning taste fibers are not affected by a lesion at this location.\n",
      "- No information in the prompt specifically addresses lacrimation or salivation being affected by a lesion at the stylomastoid foramen.\n",
      "\n",
      "Given this information, a lesion causing compression of the facial nerve at the stylomastoid foramen will cause ipsilateral:\n",
      "\n",
      "A. paralysis of the facial muscles.\n",
      "\n",
      "This conclusion is drawn solely from the information provided, which emphasizes that a lesion at this location would not impact taste, lacrimation, or salivation, as those fibers are not affected at the stylomastoid for\n"
     ]
    }
   ],
   "source": [
    "# Example query\n",
    "question = \"\"\"\n",
    "A lesion causing compression of the facial nerve at the stylomastoid foramen will cause ipsilateral\n",
    "\n",
    "A. paralysis of the facial muscles.\n",
    "B. paralysis of the facial muscles and loss of taste.\n",
    "C. paralysis of the facial muscles, loss of taste and lacrimation.\n",
    "D. paralysis of the facial muscles, loss of taste, lacrimation and decreased salivation.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "entities = extract_entities(question)\n",
    "relationships = extract_relationships(question)\n",
    "\n",
    "entity_list = []\n",
    "for entity in entities:\n",
    "  entity_list.append(entity[\"text\"])\n",
    "for relationship in relationships:\n",
    "  entity_list.append(relationship[\"subject\"])\n",
    "  entity_list.append(relationship[\"object\"])\n",
    "\n",
    "entityInfo = []\n",
    "for entity in entity_list:\n",
    "  result = query_graph(entity)\n",
    "  for r in result:\n",
    "    entityInfo.append(r[\"source\"] + \" \" + r[\"relation\"] + \" \" + r[\"target\"] + \"\\n\")\n",
    "\n",
    "prompt = question + \"\\nPlease use only the following information in the prompt to answer the question. Also please specify whether information from any other sources was used.\\n\" + \"\".join(entityInfo)\n",
    "print(prompt)\n",
    "\n",
    "response = query_openai(prompt)\n",
    "print(\"Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing ./anatomy_questions\\test_anatomy-question_000.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_000.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_001.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_001.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_002.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_002.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_003.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_003.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_004.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_004.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_005.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_005.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_006.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_006.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_007.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_007.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_008.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_008.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_009.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_009.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_010.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_010.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_011.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_011.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_012.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_012.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_013.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_013.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_014.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_014.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_015.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_015.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_016.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_016.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_017.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_017.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_018.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_018.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_019.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_019.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_020.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_020.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_021.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_021.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_022.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_022.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_023.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_023.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_024.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_024.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_025.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_025.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_026.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_026.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_027.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_027.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_028.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_028.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_029.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_029.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_030.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_030.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_031.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_031.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_032.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_032.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_033.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_033.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_034.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_034.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_035.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_035.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_036.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_036.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_037.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_037.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_038.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_038.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_039.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_039.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_040.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_040.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_041.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_041.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_042.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_042.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_043.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_043.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_044.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_044.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_045.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_045.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_046.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_046.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_047.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_047.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_048.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_048.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_049.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_049.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_050.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_050.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_051.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_051.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_052.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_052.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_053.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_053.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_054.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_054.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_055.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_055.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_056.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_056.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_057.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_057.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_058.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_058.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_059.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_059.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_060.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_060.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_061.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_061.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_062.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_062.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_063.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_063.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_064.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_064.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_065.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_065.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_066.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_066.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_067.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_067.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_068.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_068.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_069.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_069.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_070.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_070.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_071.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_071.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_072.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_072.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_073.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_073.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_074.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_074.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_075.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_075.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_076.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_076.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_077.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_077.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_078.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_078.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_079.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_079.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_080.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_080.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_081.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_081.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_082.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_082.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_083.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_083.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_084.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_084.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_085.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_085.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_086.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_086.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_087.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_087.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_088.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_088.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_089.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_089.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_090.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_090.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_091.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_091.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_092.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_092.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_093.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_093.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_094.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_094.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_095.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_095.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_096.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_096.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_097.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_097.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_098.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_098.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_099.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_099.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_100.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_100.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_101.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_101.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_102.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_102.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_103.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_103.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_104.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_104.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_105.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_105.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_106.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_106.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_107.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_107.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_108.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_108.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_109.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_109.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_110.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_110.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_111.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_111.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_112.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_112.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_113.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_113.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_114.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_114.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_115.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_115.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_116.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_116.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_117.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_117.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_118.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_118.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_119.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_119.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_120.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_120.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_121.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_121.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_122.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_122.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_123.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_123.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_124.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_124.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_125.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_125.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_126.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_126.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_127.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_127.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_128.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_128.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_129.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_129.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_130.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_130.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_131.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_131.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_132.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_132.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_133.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_133.txt\n",
      "processing ./anatomy_questions\\test_anatomy-question_134.txt\n",
      "got entities\n",
      "got relationships from graph\n",
      "Done processing ./anatomy_questions\\test_anatomy-question_134.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the directory path\n",
    "directory_path = \"./anatomy_questions\"\n",
    "output_directory = \"./anatomy_answers_stanford_nlp\"\n",
    "prompt_directory = \"./anatomy_stanford_nlp_open_ai_prompts\"\n",
    "\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for file_name in os.listdir(directory_path):\n",
    "    file_path = os.path.join(directory_path, file_name)\n",
    "    prompt_file_path = os.path.join(prompt_directory, file_name)\n",
    "    output_file_path = os.path.join(output_directory, file_name)\n",
    "    # Check if it's a file\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            print(\"processing \" + file_path)\n",
    "            question = file.read()\n",
    "            entities = extract_entities(question)\n",
    "            relationships = extract_relationships(question)\n",
    "            print(\"got entities\")\n",
    "            entity_list = []\n",
    "            for entity in entities:\n",
    "                entity_list.append(entity[\"text\"])\n",
    "            for relationship in relationships:\n",
    "                entity_list.append(relationship[\"subject\"])\n",
    "                entity_list.append(relationship[\"object\"])\n",
    "\n",
    "            entityInfo = []\n",
    "            for entity in entity_list:\n",
    "                result = query_graph(entity)\n",
    "                for r in result:\n",
    "                    entityInfo.append(r[\"source\"] + \" \" + r[\"relation\"] + \" \" + r[\"target\"] + \"\\n\")\n",
    "            print(\"got relationships from graph\")\n",
    "            prompt = question + \"\\nPlease use only the information below to answer the question. Please do not use information available from general knowledge to answer this question.\\n\" + \"\".join(entityInfo)\n",
    "            # truncate the prompt\n",
    "            prompt = prompt[:10000]  # Truncate to 10000 characters to control the size of the prompt\n",
    "            with open(prompt_file_path, 'w') as prompt_file:\n",
    "                prompt_file.write(prompt)\n",
    "            \n",
    "            response = query_openai(prompt)\n",
    "            with open(output_file_path, 'w') as output_file:\n",
    "                output_file.write(response)\n",
    "                \n",
    "            print(\"Done processing \" + file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# compare the answers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "\n",
    "source = pd.read_csv(\"./anatomy_test.csv\", header=None)\n",
    "answer_key = source.iloc[:,5]\n",
    "graph_rag_answers = pd.read_csv(\"./anatomy_answers_stanford_nlp/answers.csv\")\n",
    "graph_rag_answers = graph_rag_answers.replace(np.nan, '', regex=True)\n",
    "graph_rag_answer_key = graph_rag_answers.iloc[:,1]\n",
    "question = graph_rag_answers.iloc[:,0]\n",
    "new_df = pd.DataFrame({'question': question, 'correct_answer': answer_key, 'graph_rag_answer': graph_rag_answer_key})\n",
    "new_df['is_graph_rag_answer_correct'] = new_df['correct_answer'] == new_df['graph_rag_answer']\n",
    "new_df['graph_rag_answer_comment'] = graph_rag_answers['Comments']\n",
    "correct_count = new_df['is_graph_rag_answer_correct'].sum()\n",
    "print(correct_count)\n",
    "new_df.to_csv('./stanford_nlp_graph_answers_comparison_to_answer_key.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
